{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.2+cu111\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# About the version of package:\n",
    "\n",
    "1. If you don't want to mass you package version, you can create the virtual environment\n",
    "only for this project.\n",
    "please see the detail: https://docs.python.org/3.8/library/venv.html\n",
    "\n",
    "2. After you create virtual environment, if you use pip, you can install pipreqs package,\n",
    "it can help you to save you package version and easy to install:\n",
    "\n",
    "pip install -r .\\requirements.txt\n",
    "please see the detail：https://github.com/bndr/pipreqs\n",
    "\n",
    "I will provide my package version for you in the file.\n",
    "\n",
    "\n",
    "3. For this project, The most important is torchtext 0.9, all the minor version is works,\n",
    "torch 1.8.1 and torchtext 0.9.1 is also work.\n",
    "If you not use GPU, you can just use torch 1.8.1, which is same as Professor Li publish in blackboard.\n",
    "If you want to use GPU, please check torch version: https://pytorch.org/get-started/locally/\n",
    "and torchtext version: https://pypi.org/project/torchtext/\n",
    "\n",
    "If you have some questions, please contact me."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The data set is from kaggle youtube  statistics:\n",
    "https://www.kaggle.com/code/elem3ntary/predicting-comment-sentiment/data\n",
    "\n",
    "The code is from :https://sebastianraschka.com/blog/2021/dl-course.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comment Sentiment:\n",
    "0 represents a negative sentiment\n",
    "1 represent neutral\n",
    "2 represent positive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "VOCABULARY_SIZE = 20000\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_LAYERS = 2\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: xlabel='Sentiment'>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the data\n",
    "comment =  pd.read_csv('comments.csv')\n",
    "comment.groupby('Sentiment').count()['Comment'].plot.bar()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0     Video ID                                            Comment  \\\n0           0  wAZZ-UWGVHI  Let's not forget that Apple Pay in 2014 requir...   \n1           1  wAZZ-UWGVHI  Here in NZ 50% of retailers don’t even have co...   \n2           2  wAZZ-UWGVHI  I will forever acknowledge this channel with t...   \n3           3  wAZZ-UWGVHI  Whenever I go to a place that doesn’t take App...   \n4           4  wAZZ-UWGVHI  Apple Pay is so convenient, secure, and easy t...   \n\n   Likes  Sentiment  \n0     95          1  \n1     19          0  \n2    161          2  \n3      8          0  \n4     34          2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Video ID</th>\n      <th>Comment</th>\n      <th>Likes</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>wAZZ-UWGVHI</td>\n      <td>Let's not forget that Apple Pay in 2014 requir...</td>\n      <td>95</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>wAZZ-UWGVHI</td>\n      <td>Here in NZ 50% of retailers don’t even have co...</td>\n      <td>19</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>wAZZ-UWGVHI</td>\n      <td>I will forever acknowledge this channel with t...</td>\n      <td>161</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>wAZZ-UWGVHI</td>\n      <td>Whenever I go to a place that doesn’t take App...</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>wAZZ-UWGVHI</td>\n      <td>Apple Pay is so convenient, secure, and easy t...</td>\n      <td>34</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at data\n",
    "comment.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'Whenever I go to a place that doesn’t take Apple Pay (doesn’t happen too often), it’s such a drag. Between ‘contactless Covid’ habits and my getting the Apple Card, I’ve gotten so used to Apple Pay that I get seriously annoyed when a store doesn’t take it. It feels like a shock, it’s crazy how quickly it took over my shopping routine! I’ve officially been brainwashed by Apple because now it feels so inconvenient to even carry a physical card in my pocket.'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment.iloc[3,2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "         Unnamed: 0          Likes     Sentiment\ncount  18409.000000   18409.000000  18409.000000\nmean    9204.000000    1040.019447      1.493998\nstd     5314.364888   10651.366148      0.709928\nmin        0.000000       0.000000      0.000000\n25%     4602.000000       5.000000      1.000000\n50%     9204.000000      29.000000      2.000000\n75%    13806.000000     190.000000      2.000000\nmax    18408.000000  891372.000000      2.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Likes</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>18409.000000</td>\n      <td>18409.000000</td>\n      <td>18409.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9204.000000</td>\n      <td>1040.019447</td>\n      <td>1.493998</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5314.364888</td>\n      <td>10651.366148</td>\n      <td>0.709928</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4602.000000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9204.000000</td>\n      <td>29.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>13806.000000</td>\n      <td>190.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>18408.000000</td>\n      <td>891372.000000</td>\n      <td>2.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look the data\n",
    "comment.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0    0\nVideo ID      0\nComment       1\nLikes         0\nSentiment     0\ndtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have 1 null data in comment\n",
    "comment.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0     Video ID Comment  Likes  Sentiment\n9745        9745  bvkk3UdlfA4     NaN      1          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Video ID</th>\n      <th>Comment</th>\n      <th>Likes</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9745</th>\n      <td>9745</td>\n      <td>bvkk3UdlfA4</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at null data\n",
    "comment[comment['Comment'].isnull()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "           Comment\nSentiment         \n0             2338\n1             4638\n2            11432",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n    </tr>\n    <tr>\n      <th>Sentiment</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2338</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4638</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11432</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the other columns, and change 1 and 2 in sentiment to 1\n",
    "comment_data = comment.drop(columns = ['Unnamed: 0', 'Video ID', 'Likes'])\n",
    "comment_data.groupby('Sentiment').count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#change column name\n",
    "comment_data.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "comment_data.to_csv('youtube_data.csv', index=None)\n",
    "comment_look = pd.read_csv('youtube_data.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download English vocabulary via:\n",
    "\n",
    "- `python -m spacy download en_core_web_sm`\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# only have legacy in torchtext==0.9\n",
    "# pip install torchtext==0.9\n",
    "### Defining the feature processing\n",
    "\n",
    "TEXT = torchtext.legacy.data.Field(\n",
    "    tokenize='spacy', # default splits on whitespace\n",
    "    tokenizer_language='en_core_web_sm'\n",
    ")\n",
    "\n",
    "### Defining the label processing\n",
    "\n",
    "LABEL = torchtext.legacy.data.LabelField(dtype=torch.long)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "fields = [('TEXT_COLUMN_NAME', TEXT), ('LABEL_COLUMN_NAME', LABEL)]\n",
    "\n",
    "dataset = torchtext.legacy.data.TabularDataset(\n",
    "    path='youtube_data.csv', format='csv',\n",
    "    skip_header=True, fields=fields)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 14727\n",
      "Num Test: 3682\n"
     ]
    }
   ],
   "source": [
    "# separate into train and test set\n",
    "train_data, test_data = dataset.split(\n",
    "    split_ratio=[0.8, 0.2],\n",
    "    random_state=random.seed(RANDOM_SEED))\n",
    "\n",
    "print(f'Num Train: {len(train_data)}')\n",
    "print(f'Num Test: {len(test_data)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 12518\n",
      "Num Validation: 2209\n"
     ]
    }
   ],
   "source": [
    "# separate into train, valid and test set\n",
    "train_data, valid_data = train_data.split(\n",
    "    split_ratio=[0.85, 0.15],\n",
    "    random_state=random.seed(RANDOM_SEED))\n",
    "\n",
    "print(f'Num Train: {len(train_data)}')\n",
    "print(f'Num Validation: {len(valid_data)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TEXT_COLUMN_NAME': ['Definitely', 'trying', 'this', 'tomorrow', 'on', 'my', 'son', '.', 'This', 'cut', 'is', 'detailed', 'with', 'all', 'the', 'instructions', '.', 'Appreciate', 'you', 'sharing', 'this', 'knowledge', ',', 'stay', 'blessed', 'my', 'brother'], 'LABEL_COLUMN_NAME': '2'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Vocabulary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build the vocabulary based on the top \"VOCABULARY_SIZE\" words:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20002\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, max_size=VOCABULARY_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f'Vocabulary size: {len(TEXT.vocab)}')\n",
    "print(f'Number of classes: {len(LABEL.vocab)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 20,002 not 20,000 because of the `<unk>` and `<pad>` tokens\n",
    "- PyTorch RNNs can deal with arbitrary lengths due to dynamic graphs, but padding is necessary for padding sequences to the same length in a given minibatch so we can store those in an array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 17588), ('the', 13963), (',', 12709), ('I', 10643), ('to', 10043), ('and', 9479), ('a', 8730), ('of', 6448), ('\\n', 6438), ('!', 5617), ('is', 5523), ('you', 5371), ('in', 5036), ('it', 4599), ('for', 4536), ('that', 4096), ('this', 3756), ('\"', 2630), ('on', 2556), ('my', 2515)]\n"
     ]
    }
   ],
   "source": [
    "#Look at most common words:\n",
    "print(TEXT.vocab.freqs.most_common(20))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '.', 'the', ',', 'I', 'to', 'and', 'a', 'of']\n"
     ]
    }
   ],
   "source": [
    "#Tokens corresponding to the first 10 indices (0, 1, ..., 9):\n",
    "print(TEXT.vocab.itos[:10]) # itos = integer-to-string\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Converting a string to an integer:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.stoi['the']) # stoi = string-to-integer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Class labels:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'2': 0, '1': 1, '0': 2})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Class label count:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({'2': 7722, '1': 3174, '0': 1622})"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Data Loaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = \\\n",
    "    torchtext.legacy.data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data),\n",
    "         batch_size=BATCH_SIZE,\n",
    "         sort_within_batch=False,\n",
    "         sort_key=lambda x: len(x.TEXT_COLUMN_NAME),\n",
    "         device=DEVICE\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the iterators (note that the number of rows depends on the longest document in the respective batch):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Text matrix size: torch.Size([718, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "\n",
      "Valid:\n",
      "Text matrix size: torch.Size([8, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "\n",
      "Test:\n",
      "Text matrix size: torch.Size([6, 128])\n",
      "Target vector size: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "for batch in train_loader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break\n",
    "\n",
    "print('\\nValid:')\n",
    "for batch in valid_loader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break\n",
    "\n",
    "print('\\nTest:')\n",
    "for batch in test_loader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, batch_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        self.batch_size =  batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        #self.rnn = torch.nn.RNN(embedding_dim,\n",
    "        #                        hidden_dim,\n",
    "        #                        nonlinearity='relu')\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim, self.num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim*2, output_dim)  # 2 for bidirection\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text dim: [sentence length, batch size]\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded dim: [sentence length, batch size, embedding dim]\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_dim).to(DEVICE)\n",
    "        c0 = torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_dim).to(DEVICE)\n",
    "\n",
    "        out, _ = self.rnn(embedded)\n",
    "        out.squeeze_(0)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(input_dim=len(TEXT.vocab),\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            output_dim=NUM_CLASSES, # could use 1 for binary classification\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_layers=NUM_LAYERS\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def predict_label(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y_acctual, Y_preds = [], []\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "            Y_preds.append(predicted_labels.cpu().data.numpy())\n",
    "            Y_acctual.append(targets.cpu().data.numpy())\n",
    "    return  np.concatenate(Y_preds), np.concatenate(Y_acctual)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (769) to match target batch_size (128).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [32], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m### FORWARD AND BACK PROP\u001B[39;00m\n\u001B[0;32m     14\u001B[0m logits \u001B[38;5;241m=\u001B[39m model(text)\n\u001B[1;32m---> 15\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     18\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32md:\\python38\\lib\\site-packages\\torch\\nn\\functional.py:2693\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001B[0m\n\u001B[0;32m   2691\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2692\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 2693\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnll_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog_softmax\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32md:\\python38\\lib\\site-packages\\torch\\nn\\functional.py:2384\u001B[0m, in \u001B[0;36mnll_loss\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001B[0m\n\u001B[0;32m   2381\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2 or more dimensions (got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(dim))\n\u001B[0;32m   2383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m!=\u001B[39m target\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m-> 2384\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2385\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected input batch_size (\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m) to match target batch_size (\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), target\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m   2386\u001B[0m     )\n\u001B[0;32m   2387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m   2388\u001B[0m     ret \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mnll_loss(\u001B[38;5;28minput\u001B[39m, target, weight, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction), ignore_index)\n",
      "\u001B[1;31mValueError\u001B[0m: Expected input batch_size (769) to match target batch_size (128)."
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "\n",
    "        text = batch_data.TEXT_COLUMN_NAME.to(DEVICE)\n",
    "        labels = batch_data.LABEL_COLUMN_NAME.to(DEVICE)\n",
    "\n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "\n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_accuracy.append(float(f'{compute_accuracy(model, train_loader, DEVICE):.2f}'))\n",
    "        valid_accuracy.append(float(f'{compute_accuracy(model, valid_loader, DEVICE):.2f}'))\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
    "              f'\\nvalid accuracy: '\n",
    "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
    "\n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "\n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
    "    return prediction[0][0].item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy, label = 'train')\n",
    "plt.plot(valid_accuracy, label = 'valid')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Probability positive:')\n",
    "predict_sentiment(model, \"This is such an awesome movie, I really love it!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Probability negative:')\n",
    "1-predict_sentiment(model, \"Whenever I go to a place that doesn’t take Apple Pay (doesn’t happen too often), it’s such a drag. Between ‘contactless Covid’ habits and my getting the Apple Card, I’ve gotten so used to Apple Pay that I get seriously annoyed when a store doesn’t take it. It feels like a shock, it’s crazy how quickly it took over my shopping routine! I’ve officially been brainwashed by Apple because now it feels so inconvenient to even carry a physical card in my pocket\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_label, real_label= predict_label(model, test_loader, DEVICE)\n",
    "print(predict_label, real_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#confuion matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(real_label, predict_label)\n",
    "cf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt = '.20g')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['2','1','0'])\n",
    "ax.yaxis.set_ticklabels(['2','1','0'])\n",
    "\n",
    "plt.savefig('confusion_matrix.png')\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}